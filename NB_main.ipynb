{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB to test locally the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librairies\n",
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Packages maison\n",
    "from Scripts.main import searchmodel_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Scripts.filter_user\n",
    "import Scripts.filter_user.filter\n",
    "import Scripts.main\n",
    "importlib.reload(Scripts.main)\n",
    "importlib.reload(Scripts.filter_user.filter)\n",
    "from Scripts.main import searchmodel_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaish\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/df_for_local.csv')\n",
    "df = df.dropna(subset=['BUSINESS_DESCRIPTION','FTE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrez le pays de l'entreprise mère. ex: FR, DE, UK, US... \n",
      "\n",
      "Choisissez une valeur parmi celles disponibles pour REGION :\n",
      "['FR' 'IT']\n",
      "Exemple : 'FR' pour un seul élément, ['FR', 'DE'] pour plusieurs, ou 'all' pour tous.\n",
      "\n",
      "Choisissez une entreprise, voici quelques exemples :\n",
      "0                                     CENISIS\n",
      "1               PAVILLON DE LA GRANDE CASCADE\n",
      "2               SGA Société Gestion d'Accueil\n",
      "4     DIMO - Objets et textiles personnalisés\n",
      "6                                    RAYMONDE\n",
      "12                                   Formycom\n",
      "15                                    IDOCAPS\n",
      "16                         SAS ETHICS CONCEPT\n",
      "17                                  HEXADRONE\n",
      "18                 Aract Auvergne-Rhône-Alpes\n",
      "Name: NAME, dtype: object\n",
      "Voulez-vous appliquer un filtre sur les valeurs de la colonne FTE/REVENUE/EBITDA ?\n",
      "Choisissez une valeur parmi celles disponibles pour REGION :\n",
      "['FR' 'IT']\n",
      "Exemple : 'FR' pour un seul élément, ['FR', 'DE'] pour plusieurs, ou 'all' pour tous.\n",
      "\n",
      "Choisissez une valeur parmi celles disponibles pour SECTOR :\n",
      "['services' 'consumer' 'tmt' 'scienceHealth' 'industrials']\n",
      "Exemple : 'FR' pour un seul élément, ['FR', 'DE'] pour plusieurs, ou 'all' pour tous.\n",
      "\n",
      "Choisissez une valeur parmi celles disponibles pour SUBSECTOR :\n",
      "['professionalServices' 'technicalServices' 'education']\n",
      "Exemple : 'FR' pour un seul élément, ['FR', 'DE'] pour plusieurs, ou 'all' pour tous.\n",
      "\n",
      "Vous avez choisi : Pays = ['FR'], Secteur = ['services'], Sous-secteur = ['education']\n",
      "L'entreprise mère contient ces mots-clés : secondary education, personal development, education\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing embeddings: 100%|██████████| 82/82 [00:02<00:00, 31.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calcul de la réduction de dimension avec PCA...\n",
      "Nombre de dimensions retenues : 37 (pour 85.0% de variance)\n",
      "Top 5 des entreprises les plus similaires:\n",
      " 70                          Argos Conseils et Formation\n",
      "50                                    COLLEGE ANGELLIER\n",
      "77                                         APARC school\n",
      "44                     Professeur de Musique à Chambéry\n",
      "14    Institut National de la Jeunesse et de l'Educa...\n",
      "Name: NAME, dtype: object\n"
     ]
    }
   ],
   "source": [
    "searchmodel_main(df, model=model, tokenizer=tokenizer, top_n=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
